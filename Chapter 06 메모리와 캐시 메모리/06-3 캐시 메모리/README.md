# 06-3 캐시 메모리

## 📌 학습 목표

- 해당 챕터의 개념 정리

## ❓ 확인 문제


### Q1: 캐시 메모리의 **히트율**이 높다는 것은 무엇을 의미하는가?

1. 캐시 메모리에서 데이터를 찾을 수 있는 확률이 높다는 의미이다.
2. 캐시 메모리에서 데이터를 찾을 수 있는 확률이 낮다는 의미이다.
3. 캐시가 데이터 손실을 거의 일으키지 않는다는 의미이다.
4. 캐시 메모리의 크기가 매우 크다는 의미이다.


<details>
<summary>정답</summary>

- **히트율**이 높다는 것은 **CPU가 캐시 메모리에서 데이터를 빠르게 찾을 확률**이 높다는 의미입니다. 캐시가 데이터를 저장하고 있기 때문에 빠르게 접근할 수 있습니다.

</details>

### Q2. 다음 중 캐시 메모리와 관련된 용어에 대한 설명으로 옳지 않는 것은?

#### 1. 캐시 히트 : 캐시 메모리 내 저장된 데이터가 실제로 CPU에서 활용되는 것

#### 2. 캐시 미스 : 캐시 메모리 내 저장된 데이터가 CPU에서 필요한 데이터에 해당되지 않는 것

#### 3. 시간 지역성 : 캐시 히트의 비율

#### 4. 공간 지역성 : CPU가 사용하기 위해 접근한 메모리 공간의 근처를 이후에도 접근하려는 경향

<details>
<summary>정답</summary>

#### 3. 시간 지역성 : 캐시 히트의 비율

- 캐시 히트의 비율은 캐시 적중률입니다. 캐시 적중률은 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수) 와 같이 계산합니다.
- 시간 지역성은 CPU가 최근에 접근했던 메모리 공간에 다시 접근하려는 경향을 의미합니다.

---

</details>

### Q3. 다음 중 캐시 메모리에 대한 설명으로 틀린 것은?

#### 1. CPU와 메모리 사이에 위치해있다.


#### 2. SRAM 기반의 저장 장치이기 때문에, 시간이 지나면 저장된 데이터가 사라진다.

#### 3. CPU와 가까운 순서대로 계층을 구성하며, L1, L2, L3 캐시가 존재한다.


#### 4. 분리형 캐시는 L1캐시로 더 빠른 접근을 위해, 명령어 저장 캐시, 데이터 저장 캐시로 분리한 캐시 메모리이다.

<details>
<summary>정답</summary>

#### 2. SRAM 기반의 저장 장치이기 때문에, 시간이 지나면 저장된 데이터가 사라진다.

**[해설]**

- 시간이 지나면 저장된 데이터가 사라지는 RAM은 DRAM이다. SRAM은 데이터가 사리지지 않으며, 캐시 메모리로 SRAM을 사용하는 이유는, SRAM의 이러한 특성 때문이다.

</details>

### Q4. 캐시 메모리의 역할과 관련된 설명으로 틀린 것은?

1️. 캐시 메모리는 HDD(하드디스크)와 같은 보조기억장치에서 데이터를 빠르게 가져오는 역할을 한다.

2️. CPU의 성능 향상을 위해 캐시 메모리는 L1, L2, L3 계층으로 구분되어 있다.

3️. 캐시 메모리는 CPU와 주기억장치(RAM) 사이에서 데이터 접근 속도를 향상시키는 역할을 한다.

4. 캐시 메모리가 없으면 CPU는 직접 RAM에서 데이터를 가져와야 하므로 실행 속도가 느려질 수 있다.

<details>
<summary>정답</summary>


- **1. 캐시 메모리는 HDD(하드디스크)와 같은 보조기억장치에서 데이터를 빠르게 가져오는 역할을 한다. X**

  - 캐시 메모리는 주기억장치(RAM)에서 데이터를 가져와 CPU의 속도를 향상시키는 역할을 합니다.
  - HDD(보조기억장치)와 관련된 속도 향상 기술은 디스크 캐시(Disk Cache) 또는 **버퍼(Buffer)**입니다.

**[해설]**


**2. CPU의 성능 향상을 위해 캐시 메모리는 L1, L2, L3 계층으로 구분되어 있다.**

- L1 캐시: 가장 빠르지만 용량이 가장 작음 (CPU 내부)
- L2 캐시: L1보다 용량이 크고 속도는 상대적으로 느림
- L3 캐시: 가장 용량이 크지만 상대적으로 속도가 느림

**3️. 캐시 메모리는 CPU와 주기억장치(RAM) 사이에서 데이터 접근 속도를 향상시키는 역할을 한다.**  
 **4. 캐시 메모리가 없으면 CPU는 직접 RAM에서 데이터를 가져와야 하므로 실행 속도가 느려질 수 있다.**

- CPU와 RAM 사이에서 자주 사용하는 데이터를 저장하여 빠른 접근이 가능하도록 함
- CPU가 데이터를 직접 RAM에서 가져오는 것보다 훨씬 빠르게 처리할 수 있음

---

</details>

### Q5. 참조 지역성과 관련된 설명으로 적절하지 않은 것은?

#### 1️⃣ 시간 지역성은 최근 사용한 데이터가 다시 사용될 가능성이 높다는 개념이다.

#### 2️⃣ 공간 지역성은 특정 주소를 접근하면 그 주변 주소도 접근할 가능성이 높다는 개념이다.

#### 3️⃣ 참조 지역성 원리를 활용하면 캐시 적중률을 낮출 수 있다.

#### 4️⃣ 루프(loop) 구조의 코드가 참조 지역성을 잘 활용하는 대표적인 예시이다.

<details>
<summary>정답</summary>

<h4>3️⃣ 참조 지역성 원리를 활용하면 캐시 적중률을 낮출 수 있다.</h4>

- 참조 지역성을 잘 활용하면 캐시 적중률이 **높아지고**, 성능이 **향상**됨.

---

**[해설]**

### 참조 지역성(Locality of Reference) 정리

#### 시간 지역성(Temporal Locality)


- 최근에 접근했던 메모리 공간에 다시 접근하려는 경향
- **예시**:
  - 변수 재사용
  - 함수 호출

#### 공간 지역성(Spatial Locality)

- 접근한 메모리 공간 근처를 접근하려는 경향
- **예시**:
  - 배열(연속된 메모리에 접근)
  - 코드 실행(연속된 명령어를 수행)

### ※ 루프 구조

```java
for (int i = 0; i < 100; i++) { // 같은 변수(i)를 재사용 (시간 지역성)
    sum += arr[i];  // 배열의 연속된 메모리를 순차적으로 접근 (공간 지역성)
}
```

</details>

### Q6. 참조 지역성의 원리 두 가지에 대해 설명하시오오

<details>
<summary>정답</summary>

#### 시간 지역성 - CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.

최근에 사용된 데이터나 명령어는 가까운 미래에도 다시 사용될 가능성이 높다는 원리

예시) 반복문에서 같은 변수나 명령어가 여러 번 실행되는 경우, 최근 사용한 파일이나 프로그램이 다시 실행될 확률이 높은 경우

#### 공간 지역성 - CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.

현재 참조된 메모리 주소와 가까운 주소의 데이터도 곧 접근될 가능성이 높다는 원리

예시) 배열에서 순차적으로 데이터를 접근하는 경우, 프로그램이 실행될 때 코드가 연속된 메모리 블록에 저장되어 있어 다음 명령어가 인접한 메모리에서 실행되는 경우, 캐시 메모리에서 블록 단위로 데이터를 로드하는 이유

- 캐시 메모리에서 블록 단위로 데이터를 로드하는 이유

  공간지역성을 활용하여 효율적으로 성능 최적화 가능해짐, CPU가 메모리에 접근하는 횟수를 줄일 수 있어 성능이 좋아짐, 캐시 미스 감소

---

</details>

### Q7. 다음 중 캐시 미스가 발생하는 상황으로 옳지 않은 것은?

#### 1. 프로그램이 최초로 실행되어 어떤 데이터를 필요로 하는지 예측할 수 없는 경우
#### 2. 캐시 메모리 주소 할당 방식 등의 문제로 둘 이상의 데이터가 같은 공간에 할당되어 하나가 덮어쓰인 경우
#### 3. 캐시 메모리 공간이 부족하여 기존 데이터를 제거한 경우
#### 4. cpu가 필요로 하는 캐시 데이터를 정상적으로 참조한 경우

<details>
	<summary>정답</summary>
	<h4>4. cpu가 필요로 하는 캐시 데이터를 정상적으로 참조한 경우</h4>
	---
	
	- 필요로 하는 캐시 데이터를 정상적으로 참조한 경우는 캐시 미스가 아닌 캐시 히트에 해당한다
	- 나머지 선지는 각각 컴펄서리 미스(Compulsory Miss), 컨플릭트 미스(Conflict Miss), 용량 미스(Capacity Miss)에 해당한다.
		- 컴펄서리 미스: 프로그램의 최초 실행 등의 원인으로 CPU가 어떤 데이터를 필요로 하는지 예측할 수 없어 참조 지역성 바탕으로 캐시 메모리에 데이터를 할당하지 못했을 때 발생
		- 컨플릭트 미스: 캐시 매핑 방식으로 인해 서로 다른 주소가 같은 캐시 블록에 할당되어 기존의 주소가 교체되어 유실된 경우
		- 용량 미스: 캐시 메모리의 용량이 모자라 기존 데이터를 제거한 뒤 새로운 데이터를 할당해 기존 데이터에 접근하지 못하게 되는 경우
</details>

### Q8. ‘캐시 메모리가 메모리의 일부를 복사하여 저장하는 과정’ 은 프로그램 실행의 어느 단계에서 일어나는가?

<details> 
<summary>정답</summary>

✅ 프로그램 실행 단계에서 "메모리 접근"이 일어날 때 발생한다. 
- 프로그램이 실행될 때:
    1. CPU가 명령어를 가져오려고(Instruction Fetch) 메모리에 접근하거나,
    2. 데이터를 읽거나 쓸 때(Data Fetch/Store) 메모리에 접근하면,
- 캐시 메모리 시스템은 다음을 수행:
    * 해당 데이터나 명령어가 캐시에 있는지 확인 (Cache Hit)
    * 없으면 메인 메모리에서 읽어와 캐시에 복사 (Cache Miss → Load)

즉, **캐시에 메모리 내용을 복사하는 과정은 프로그램 실행 중 CPU가 메모리에 접근하는 순간마다 동적으로 이루어진다.**

</details> 


### **Q9. 캐시 메모리는 데이터 접근 속도를 향상시키지만, 과도하게 많아지면 오히려 성능 저하를 일으킬 수 있습니다. 캐시 메모리로 인해 성능 저하가 발생하는 이유를 설명하세요.**

<details>  
<summary>정답</summary>

- **캐시 크기 증가로 인한 접근 속도 저하**
  - 캐시 메모리가 커지면 데이터 탐색 시간이 길어져 빠르게 접근하기 어려워짐.
  - 특히 하위 레벨 캐시가 지나치게 커지면 조회 속도가 느려져 성능이 떨어질 수 있음.

- **캐시 미스 증가**
  - 캐시 크기가 과도하게 크면 필요한 데이터를 빠르게 찾지 못할 가능성이 높아짐.
  - 캐시 히트율이 낮아져 느린 저장장치 접근이 잦아지고, 전체 성능이 저하됨.

- **캐시 갱신 비용 증가**
  - 저장 공간이 부족할 때 기존 데이터를 제거하고 새 데이터를 캐시에 로딩하는 작업이 빈번해짐.
  - 이러한 반복 작업으로 인해 성능 저하가 발생할 수 있음.

- **멀티 프로세서 환경에서의 데이터 일관성 유지 비용**
  - 여러 처리 장치가 동일 데이터를 캐시에 저장하면, 데이터 일관성 유지(캐시 일관성 프로토콜)를 위한 추가 연산이 발생하여 성능이 저하될 수 있음.

</details>

### **Q10. 지문을 읽고 해당 문제의 원인과 그에 대한 해결책에 대해 설명해주세요.**

> 한 게임 개발사가 신규 패치를 배포한 이후, 일부 사용자들의 게임 성능이 갑자기 저하되는 문제가 발생했다.  
> 패치 이전에는 부드럽게 실행되던 게임이 갑작스럽게 버벅이거나 프레임 드랍 현상이 심화되었으며,  
> 특히 자주 사용되는 게임 리소스를 로딩하는 시간이 증가하였다.  
> 개발팀이 조사한 결과, 패치 과정에서 특정 최적화 기법이 비활성화된 것으로 확인되었다.  
> 이 문제의 원인은 무엇이며, 어떻게 해결할 수 있을까?

---

<details>  
<summary>정답</summary>

### **문제 원인**
- 패치 과정에서 **캐시 메모리 최적화 기법이 비활성화됨**.  
- 자주 사용하는 **게임 리소스(텍스처, 모델, 사운드 데이터 등)**가 **CPU 캐시 또는 메모리에서 사전 로딩되지 않음**.  
- 그 결과, 해당 데이터가 **느린 주기억장치(RAM) 또는 심지어 디스크에서 직접 로드**되면서 성능 저하 발생.  

---

### **해결 방법**

- **캐시 친화적인 데이터 배치**  
  - CPU 캐시의 **공간 지역성(Spatial Locality)**을 고려하여 데이터를 **연속된 메모리 영역에 배치**하여 캐시 효율을 높임.  

- **프리페칭(Prefetching) 최적화**  
  - 자주 접근하는 데이터(게임 리소스, UI 요소)를 **미리 캐시에 로드**하여 캐시 미스를 최소화함.  

- **캐시 유지 정책 조정**  
  - 중요한 리소스가 캐시에서 **너무 빨리 제거되지 않도록** 캐시 유지 정책(Cache Eviction Policy) 조정.  

- **메모리 풀링(Pooling) 활용**  
  - 게임 실행 중 자주 할당/해제되는 객체를 미리 할당해두고 재사용하여 캐시 히트율을 높임.  

---

### **실제 사례: DOOM(2016) 게임 최적화**  

- **사건 개요**  
  > DOOM(2016) 개발팀은 초고속 성능을 유지하기 위해 **데이터 캐싱 최적화**를 적극 활용.  
  > 그러나 초기 빌드에서는 **리소스 로딩 방식이 비효율적**이어서 일부 구간에서 **프레임 드랍 발생**.  

- **발생한 문제**  
  > 텍스처, 오브젝트 데이터가 **캐시에 미리 적재되지 않아** 자주 참조되는 데이터도 매번 RAM에서 불러와야 했음.  
  > 그로 인해 **캐시 미스 증가 → 메모리 대역폭 사용 증가 → 성능 저하** 발생.  

- **ID Software의 대응**  
  > **프리페칭과 캐시 친화적 데이터 배치 최적화** 적용.  
  > GPU 및 CPU 캐시 효율을 높이기 위해 **텍스처를 연속된 블록으로 배치**하여 성능 향상.  

</details>

## 📝 사용법

### 이렇게 활용해 보세요! ✨

1. ❓ 확인 문제 아래에 본인이 만든 질문을 추가하세요.
2. 설명이 길어질 경우, 따로 마크다운 파일을 만들고 링크를 함께 추가해 주세요! 🔗

### 🔗 링크 추가 방법

1. 먼저 질문을 작성합니다.
2. 링크를 적용할 문장을 마우스로 선택합니다.
3. URL을 붙여넣습니다.
4. 마크다운 형식으로 `[내용](링크)` 형태로 정리됩니다.

